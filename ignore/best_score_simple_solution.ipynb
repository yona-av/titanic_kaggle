{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7e0488df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import sys\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "import xgboost\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# import pre-processing modules \n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel \n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "# import classifiers\n",
    "# scale robust\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# scale sensitive\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# import evaluation modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support, classification_report\n",
    "from sklearn.metrics import  RocCurveDisplay, roc_auc_score, auc, roc_curve, PrecisionRecallDisplay, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8751f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(r\"C:/Users/Yehonatan/PycharmProject/DS/projects/titanic/ignore/test.csv\")\n",
    "train_set = pd.read_csv(r\"C:/Users/Yehonatan/PycharmProject/DS/projects/titanic/ignore/train.csv\")\n",
    "\n",
    "df_original = pd.concat([train_set,test_set], axis=0, ignore_index=True )\n",
    "df_train = (train_set.copy()).rename(columns=str.lower)\n",
    "df_test = (test_set.copy()).rename(columns=str.lower)\n",
    "\n",
    "df = (df_original.copy()).rename(columns=str.lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4b1461b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse title and fam name from df \n",
    "def parse_name(df):\n",
    "    last_name = df['name'].apply(lambda x : x.split(', ')[0])\n",
    "    temp = df['name'].apply(lambda x : x.split(', ')[1])\n",
    "    title = temp.apply(lambda x : x.split('.')[0])\n",
    "    return title, last_name\n",
    "\n",
    "def cat_to_numeric(df):\n",
    "    cat_columns = df.select_dtypes(['object', 'category']).columns\n",
    "    df[cat_columns] = df[cat_columns].apply(lambda x: pd.factorize(x)[0])\n",
    "    return df \n",
    "\n",
    "def pvalue_filter(target_df, features_df, alpha): # returns a list of columns that are possible drop, p_val > alpha, corr, pval\n",
    "    features_columns_names = list(features_df)\n",
    "    target_column_name = list(target_df)\n",
    "    features_np = features_df.to_numpy()\n",
    "    target_np = target_df.to_numpy()\n",
    "    drop_index = []\n",
    "    p_val_list =[]\n",
    "    corr_list = []\n",
    "    \n",
    "    for i in range(len(features_columns_names)):\n",
    "        corr, p_val = sp.stats.pearsonr(features_np[:,i], target_np)\n",
    "        corr_list.append(round(corr,3))\n",
    "        if p_val > alpha:           # accept the null hypothesis, no statisitcal significance  \n",
    "            drop_index.append(i)\n",
    "            p_val_list.append(p_val)\n",
    "            \n",
    "    drop_col = [features_columns_names[i] for i in drop_index]\n",
    "    return drop_col, corr_list, p_val_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f1f47a",
   "metadata": {},
   "source": [
    "# deal with age Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8c717670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df  age nans 263\n",
      "df  age nans 255\n",
      "df  age nans 56\n",
      "df  age nans 49\n",
      "df  age nans 44\n",
      "df  age nans 0\n"
     ]
    }
   ],
   "source": [
    "age_nan = df[df['age'].isna()]  \n",
    "print('df  age nans',df['age'].isna().sum())\n",
    "title, last_name = parse_name(df)\n",
    "df['title'] = title\n",
    "df['last_name'] = last_name\n",
    "\n",
    "###### Deal with Masters  ############################################\n",
    "\n",
    "child_mean =  round(df[df[\"age\"] < 15 ]['age'].mean(numeric_only=True),2)\n",
    "df.loc[df['title'] == 'Master','age'] = df.loc[df['title'] == 'Master','age'].fillna(child_mean)\n",
    "age_nan = df[df['age'].isna()] # update age_nan\n",
    "print('df  age nans',df['age'].isna().sum())\n",
    "\n",
    "####### Deal with lone passengers ############################################\n",
    "male_mean =  round(df[df[\"sex\"] == 'male']['age'].mean(numeric_only=True),2)\n",
    "female_mean =  round(df[df[\"sex\"] == 'female']['age'].mean(numeric_only=True),2)\n",
    "\n",
    "df.loc[(df['sibsp'] == 0) & (df['parch'] == 0) & (df['sex'] == 'male'), 'age'\n",
    "      ]= df.loc[(df['sibsp'] == 0) & (df['parch'] == 0) & (df['sex'] == 'male'), 'age'].fillna(male_mean)\n",
    "\n",
    "df.loc[(df['sibsp'] == 0) & (df['parch'] == 0) & (df['sex'] == 'female'), 'age'\n",
    "      ]= df.loc[(df['sibsp'] == 0) & (df['parch'] == 0) & (df['sex'] == 'female'), 'age'].fillna(female_mean)\n",
    "\n",
    "age_nan = df[df['age'].isna()] # update age_nan\n",
    "print('df  age nans',df['age'].isna().sum())\n",
    "\n",
    "########## ONE companion (sibling or spouse) ############################################################\n",
    "\n",
    "one_comp_mean = round(df[(df['sibsp'] == 1) & (df['parch'] == 0)]['age'].mean(numeric_only=True),2)\n",
    "one_comp_df = df[(df['sibsp'] == 1) & (df['parch'] == 0)]\n",
    "one_comp_df_nan = one_comp_df[one_comp_df['age'].isna()]\n",
    "\n",
    "for i in range(len(one_comp_df_nan)):\n",
    "    for j in range(len(one_comp_df)):\n",
    "        #compare last name and make sure it isn't the same passenger\n",
    "        if (one_comp_df_nan['last_name'].iloc[i] == one_comp_df['last_name'].iloc[j]  \n",
    "            and one_comp_df_nan['passengerid'].iloc[i] != one_comp_df['passengerid'].iloc[j]):\n",
    "            \n",
    "            ix_nan = one_comp_df_nan['passengerid'].iloc[i] - 1 \n",
    "            ix = one_comp_df['passengerid'].iloc[j] -1 \n",
    "            df.at[ix_nan,'age'] = df.at[ix,'age']\n",
    "            \n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "print('df  age nans',df['age'].isna().sum())\n",
    "\n",
    "########## Special cases ############################################################\n",
    "# sage family\n",
    "#parents\n",
    "df.at[1233, 'age'] = male_mean\n",
    "df.at[1256, 'age'] = female_mean\n",
    "#kids\n",
    "df[df['last_name'] == 'Sage']['age'] = df[df['last_name'] == 'Sage']['age'].fillna(child_mean)\n",
    "\n",
    "# lebfre family\n",
    "df.at[1023, 'age'] = female_mean\n",
    "#kids\n",
    "df[df['last_name'] == 'lebfre']['age'] = df[df['last_name'] == 'lebfre']['age'].fillna(child_mean)\n",
    "\n",
    "#jhonston family\n",
    "#parents\n",
    "df.at[783, 'age'] = male_mean\n",
    "df.at[924, 'age'] = female_mean\n",
    "\n",
    "age_nan = df[df['age'].isna()] # update age_nan\n",
    "print('df  age nans',df['age'].isna().sum())\n",
    "\n",
    "############ deal with the rest ########################################################################################\n",
    "df.loc[df['sex'] == 'male', 'age'] = df.loc[df['sex'] == 'male', 'age'].fillna(male_mean)\n",
    "df.loc[df['sex'] == 'female', 'age'] = df.loc[df['sex'] == 'female', 'age'].fillna(female_mean)\n",
    "age_nan = df[df['age'].isna()] # update age_nan\n",
    "print('df  age nans',df['age'].isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc362424",
   "metadata": {},
   "source": [
    "# deal with cabin Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "25f26a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df  cabin nans 1014\n",
      "df cabin nans updated 998\n",
      "df cabin nans updated 1\n",
      "df cabin nans updated 0\n"
     ]
    }
   ],
   "source": [
    "cabin = df[~df['cabin'].isna()]\n",
    "cabin_nan =  df[df['cabin'].isna()]\n",
    "print('df  cabin nans',df['cabin'].isna().sum())\n",
    "\n",
    "################## deal with cabin nan by comparing the ticket number #########################################################\n",
    "for t in range(len(cabin['ticket'])):\n",
    "    for n in range(len(cabin_nan['ticket'])):\n",
    "        if cabin['ticket'].iloc[t] == cabin_nan['ticket'].iloc[n] :\n",
    "           \n",
    "            ix = cabin['passengerid'].iloc[t] - 1    \n",
    "            ix_nan = cabin_nan['passengerid'].iloc[n] - 1 \n",
    "            if ix != ix_nan:\n",
    "                # update the value of cabin_nan in the df\n",
    "                df.at[ix_nan,'cabin'] = df.at[ix,'cabin']\n",
    "\n",
    "\n",
    "cabin_nan =  df[df['cabin'].isna()] # update cabin_nan\n",
    "print('df cabin nans updated',len(cabin_nan))    \n",
    "\n",
    "################## deal with rest of Nans #########################################################\n",
    "\n",
    "# combine for each passenger 'pclass' and 'fare' and assume \n",
    "#that if they paid the same and were at the same class they were at the sme cabin\n",
    "\n",
    "cabin_nan['cabin'] = cabin_nan['pclass'].astype('string') + cabin_nan['fare'].astype('string')\n",
    "for i in range(len(cabin_nan)):\n",
    "    ix = cabin_nan['passengerid'].iloc[i] - 1\n",
    "    df.at[ix,'cabin'] = cabin_nan['cabin'].iloc[i]\n",
    "\n",
    "cabin_nan =  df[df['cabin'].isna()] # update cabin_nan\n",
    "print('df cabin nans updated',len(cabin_nan))   \n",
    "\n",
    "########### special case #############################################################################\n",
    "df.at[1043,'cabin'] = 38.05 # explain 3 is pclass and added to fare value 8.05 \n",
    "cabin_nan =  df[df['cabin'].isna()] # update cabin_nan\n",
    "print('df cabin nans updated',len(cabin_nan))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "065201bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\n",
    "                                   'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "df['title'] = df['title'].replace(['Mlle','Ms' ], 'Miss')\n",
    "df['title'] = df['title'].replace('Mme', 'Mrs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95c87b1",
   "metadata": {},
   "source": [
    "# other Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f6b59530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill fare nan as the average of 3 class . \n",
    "\n",
    "t_class_mean = round(df[df[\"pclass\"] == 3 ]['fare'].mean(numeric_only=True),2)\n",
    "df.at[1043, 'fare'] = t_class_mean\n",
    "\n",
    "# fill nan embarked to be as most common embarking place \n",
    "df.at[61, 'embarked'] = 'S'\n",
    "df.at[829, 'embarked'] = 'S'\n",
    "\n",
    "survived = df['survived']\n",
    "passenger_id = df['passengerid'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e708cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = [1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "labels_fare = np.linspace(1,13,13, dtype = 'int')\n",
    "labels_age = np.linspace(1,10,10, dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e1e4ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fare'] = pd.qcut(df['fare'], 13, labels= labels_fare)\n",
    "df['age'] = pd.qcut(df['age'], 10, labels = labels_age) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "25fee065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1       12\n",
       "2        4\n",
       "3       11\n",
       "4        4\n",
       "        ..\n",
       "1304     4\n",
       "1305    13\n",
       "1306     1\n",
       "1307     4\n",
       "1308     8\n",
       "Name: fare, Length: 1309, dtype: category\n",
       "Categories (13, int64): [1 < 2 < 3 < 4 ... 10 < 11 < 12 < 13]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ab5938cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   passengerid  1309 non-null   int64   \n",
      " 1   survived     891 non-null    float64 \n",
      " 2   pclass       1309 non-null   int64   \n",
      " 3   name         1309 non-null   object  \n",
      " 4   sex          1309 non-null   object  \n",
      " 5   age          1309 non-null   category\n",
      " 6   sibsp        1309 non-null   int64   \n",
      " 7   parch        1309 non-null   int64   \n",
      " 8   ticket       1309 non-null   object  \n",
      " 9   fare         1309 non-null   category\n",
      " 10  cabin        1309 non-null   object  \n",
      " 11  embarked     1309 non-null   object  \n",
      " 12  title        1309 non-null   object  \n",
      " 13  last_name    1309 non-null   object  \n",
      "dtypes: category(2), float64(1), int64(4), object(7)\n",
      "memory usage: 126.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e902cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cat_to_numeric(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ada50785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   passengerid  1309 non-null   int64  \n",
      " 1   survived     891 non-null    float64\n",
      " 2   pclass       1309 non-null   int64  \n",
      " 3   name         1309 non-null   int64  \n",
      " 4   sex          1309 non-null   int64  \n",
      " 5   age          1309 non-null   int64  \n",
      " 6   sibsp        1309 non-null   int64  \n",
      " 7   parch        1309 non-null   int64  \n",
      " 8   ticket       1309 non-null   int64  \n",
      " 9   fare         1309 non-null   int64  \n",
      " 10  cabin        1309 non-null   int64  \n",
      " 11  embarked     1309 non-null   int64  \n",
      " 12  title        1309 non-null   int64  \n",
      " 13  last_name    1309 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 143.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8ea4cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # eliminate low count frequency\n",
    "# df['cabin_frequency'] = df.groupby('cabin')['cabin'].transform('count')\n",
    "# # all the cabins that have freq less than 3 \n",
    "# for i in range(len(df)):\n",
    "#     if df['cabin_frequency'].iloc[i] < 3:\n",
    "#         new_cabin = list(df['cabin'].iloc[i])[0]\n",
    "#         df.at[i,'cabin'] = new_cabin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db91786",
   "metadata": {},
   "source": [
    "# check correlation and p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6c7ffa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived       1.000000\n",
       "sex            0.543351\n",
       "title          0.405788\n",
       "cabin          0.218673\n",
       "embarked       0.106811\n",
       "parch          0.081629\n",
       "fare           0.077185\n",
       "age            0.054115\n",
       "last_name      0.017314\n",
       "passengerid   -0.005007\n",
       "name          -0.005007\n",
       "sibsp         -0.035322\n",
       "ticket        -0.047298\n",
       "pclass        -0.338481\n",
       "Name: survived, dtype: float64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_mat = df.corr()\n",
    "corr_mat['survived'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d8aa440c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop those columns p-value < 0.005 ['passengerid', 'name', 'age', 'sibsp', 'ticket', 'last_name']\n"
     ]
    }
   ],
   "source": [
    "df_train = df.iloc[:890,:]\n",
    "\n",
    "drop_col, corr_list, p_val_list = pvalue_filter(df_train['survived'], df_train.drop(columns=['survived']), 0.05)\n",
    "print('drop those columns p-value < 0.005',drop_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "62201a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['survived','passengerid', 'name', 'sibsp', 'ticket', 'last_name']) \n",
    "# 'name', 'sibsp', 'ticket' dropped those columns logic in unstandradized models file p value filter  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb450664",
   "metadata": {},
   "source": [
    "# scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1a1fef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_columns_selector = selector(dtype_exclude=int)\n",
    "categorical_columns_selector = selector(dtype_include=int)\n",
    "\n",
    "numerical_columns = numerical_columns_selector(df)\n",
    "categorical_columns = categorical_columns_selector(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cb0a82e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['pclass', 'sex', 'age', 'parch', 'fare', 'cabin', 'embarked', 'title']\n"
     ]
    }
   ],
   "source": [
    "print(numerical_columns)\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ad759712",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "numerical_preprocessor = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "    ('standard_scaler', numerical_preprocessor, numerical_columns)])\n",
    "\n",
    "\n",
    "model = make_pipeline(preprocessor, RandomForestClassifier(random_state=9) )\n",
    "\n",
    "# divide back into train test sets \n",
    "df_train = df.iloc[:890,:]\n",
    "df_test = df.iloc[891:,:]\n",
    "\n",
    "x_train = df_train\n",
    "y_train = survived.iloc[:890]\n",
    "\n",
    "\n",
    "x_test = df_test\n",
    "y_test = survived.iloc[891:]\n",
    "\n",
    "model = model.fit(x_train, y_train)\n",
    "y_train_pred = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "538c219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_avg_accuracy : 0.82\n"
     ]
    }
   ],
   "source": [
    "cv_5_accuracy = cross_val_score(model, x_train , y_train, cv=5, scoring='accuracy')\n",
    "# cv_5_precision = cross_val_score(model, x_train , y_train, cv=5, scoring='precision')\n",
    "# cv_5_recall = cross_val_score(model, x_train , y_train, cv=5, scoring='recall')\n",
    "# cv_5_f1 = cross_val_score(model, x_train , y_train, cv=5, scoring='f1')\n",
    "\n",
    "print('cv_avg_accuracy :', np.round(cv_5_accuracy.mean(),3))\n",
    "# print('cv_avg_precision', np.round(cv_5_precision.mean(),3))\n",
    "# print('cv_avg_recall', np.round(cv_5_recall.mean(),3))\n",
    "# print('cv_avg_fscore :', np.round(cv_5_f1.mean(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "cb1d440a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[475  73]\n",
      " [102 240]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.87      0.84       548\n",
      "         1.0       0.77      0.70      0.73       342\n",
      "\n",
      "    accuracy                           0.80       890\n",
      "   macro avg       0.79      0.78      0.79       890\n",
      "weighted avg       0.80      0.80      0.80       890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(model, x_train, y_train, cv=3)\n",
    "cnf_mx = confusion_matrix(y_train, y_pred)\n",
    "print(cnf_mx)\n",
    "print(classification_report(y_train, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fafb021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred = y_test_pred.astype(int)\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({'Passengerid': passenger_id[891:], 'Survived': y_test_pred})\n",
    "submission_df.to_csv('titanic_pred_44.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff19a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
