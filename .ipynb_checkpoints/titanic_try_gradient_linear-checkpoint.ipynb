{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04730771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import sys\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "%matplotlib inline\n",
    "\n",
    "# import pre-processing modules \n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel \n",
    "\n",
    "# import classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# import evaluation modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d38ac8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(r\"C:/Users/Yehonatan/PycharmProject/DS/projects/titanic/ignore/test.csv\")\n",
    "train_set = pd.read_csv(r\"C:/Users/Yehonatan/PycharmProject/DS/projects/titanic/ignore/train.csv\")\n",
    "df_original = pd.concat([train_set,test_set], axis=0, ignore_index=True )\n",
    "\n",
    "df_train = (train_set.copy()).rename(columns=str.lower)\n",
    "df_test = (test_set.copy()).rename(columns=str.lower)\n",
    "\n",
    "df = (df_original.copy()).rename(columns=str.lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de9059f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse title and fam name from df \n",
    "def parse_name(df):\n",
    "    last_name = df['name'].apply(lambda x : x.split(', ')[0])\n",
    "    temp = df['name'].apply(lambda x : x.split(', ')[1])\n",
    "    title = temp.apply(lambda x : x.split('.')[0])\n",
    "    return title, last_name\n",
    "\n",
    "def cat_to_numeric(df):\n",
    "    cat_columns = df.select_dtypes(['object']).columns\n",
    "    df[cat_columns] = df[cat_columns].apply(lambda x: pd.factorize(x)[0])\n",
    "    return df \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef288aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df  age nans 263\n"
     ]
    }
   ],
   "source": [
    "# work on df nan and then concat with original df_train and sort by ID\n",
    "age_nan = df[df['age'].isna()]\n",
    "#age_nan.info()\n",
    "#age_nan = age_nan.sort_values(by=['sex'],ascending=True)\n",
    "#age_nan = age_nan.sort_values(by=['sibsp'],ascending=False).reset_index(drop=True)\n",
    "print('df  age nans',df['age'].isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6b8464",
   "metadata": {},
   "source": [
    "## deal with age nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "acc5daee",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Deal with masters  ############################################\n",
    "title, last_name = parse_name(age_nan)\n",
    "title = title[title == 'Master']\n",
    "master_index = title.index.to_numpy()\n",
    "\n",
    "df_young = df[df[\"age\"] < 15 ]\n",
    "child_mean = round(df_young['age'].mean(),2)\n",
    "       \n",
    "for i in master_index:\n",
    "    df.at[i,'age'] = child_mean \n",
    "\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "####### DEAL  with lone passengers ############################################\n",
    "\n",
    "l_p_t = age_nan[age_nan['sibsp'] == 0]\n",
    "lone_pass = l_p_t[l_p_t['parch'] == 0] # passengers who travel alone and cant determine their age by relatives\n",
    "#lone_pass\n",
    "\n",
    "# calc mean by gender\n",
    "df_male = df[df['sex'] == 'male']\n",
    "df_female = df[df['sex'] == 'female']\n",
    "male_mean = round(df_male['age'].mean(),2)\n",
    "female_mean = round(df_female['age'].mean(),2)\n",
    "\n",
    "lone_pass_male = lone_pass[lone_pass['sex'] == 'male']\n",
    "lone_pass_female = lone_pass[lone_pass['sex'] == 'female']\n",
    "\n",
    "l_p_m_index = (lone_pass_male.index).to_numpy()\n",
    "l_p_f_index = (lone_pass_female.index).to_numpy()\n",
    "\n",
    "for m in l_p_m_index:\n",
    "    df.at[m,'age'] = male_mean\n",
    "\n",
    "for f in l_p_f_index:\n",
    "    df.at[f,'age'] = female_mean\n",
    "    \n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "\n",
    "\n",
    "########## ONE companion ############################################################\n",
    "# one companion in nan df # assign the age of the companion tot the nan \n",
    "one_comp_nan = age_nan[age_nan['parch'] == 0] \n",
    "one_comp_nan = one_comp_nan[one_comp_nan['sibsp'] == 1]\n",
    "title_ocn, last_name_ocn = parse_name(one_comp_nan)\n",
    "ocn_index = (title_ocn.index).to_numpy()\n",
    "\n",
    "\n",
    "one_comp = df[df['parch'] == 0] # one companion in general df may contain istself. but some companions are both nan in age\n",
    "one_comp = one_comp[one_comp['sibsp'] == 1]\n",
    "#one_comp = one_comp[~one_comp['age'].isna()]\n",
    "title_oc, last_name_oc = parse_name(one_comp)\n",
    "oc_index = (title_oc.index).to_numpy()\n",
    "\n",
    "for l in range(len(one_comp_nan)):\n",
    "    for i in range(len(one_comp)):\n",
    "        \n",
    "        if (list(last_name_ocn)[l] == list(last_name_oc)[i] and ocn_index[l] != oc_index[i]): #ensures same last name and not same person\n",
    "        \n",
    "            if df.at[oc_index[i],'age'] != float('nan'):\n",
    "                df.at[ocn_index[l],'age'] =  df.at[oc_index[i],'age'] \n",
    "            if list(title_ocn)[l] == 'Mrs' : # she and her husbnad are adults and get the adult average\n",
    "                df.at[ocn_index[l],'age'] = female_mean\n",
    "                df.at[oc_index[i],'age'] = male_mean\n",
    "            if list(title_ocn)[l] == 'Miss': # she is a miss and I assume that travels with a sibling so get young average\n",
    "                df.at[ocn_index[l],'age'] = child_mean\n",
    "                df.at[oc_index[i],'age'] = child_mean\n",
    "            if list(title_ocn)[l] == 'Mr' and list(title_oc)[i] != 'Mrs':\n",
    "                df.at[ocn_index[l],'age'] = child_mean\n",
    "                df.at[oc_index[i],'age'] = child_mean\n",
    "\n",
    "\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "# notice there are only two famillies with 3 siblings travelling together I assume they are all young <15.\n",
    "three_siblings = age_nan[age_nan['parch'] == 0] \n",
    "three_siblings = three_siblings[three_siblings['sibsp'] == 2]\n",
    "index_temp = three_siblings.index.to_numpy()\n",
    "for i in index_temp:\n",
    "    df.at[i,'age'] = child_mean\n",
    "\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "########### Hand fill age nans #######################################################\n",
    "\n",
    "\n",
    "# hand fill, thought it will be quicker than thinking about an algo  \n",
    "#parents\n",
    "df.at[1233, 'age'] = male_mean\n",
    "df.at[1256, 'age'] = female_mean\n",
    "#kids\n",
    "sages = df[df['ticket'] == 'CA. 2343']\n",
    "sages = sages[sages['age'].isna()]\n",
    "\n",
    "index_temp = sages.index.to_numpy()\n",
    "for i in index_temp:\n",
    "    df.at[i,'age'] = child_mean\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "df.at[1023, 'age'] = female_mean\n",
    "lebfre = df[df['ticket'] == '4133']\n",
    "lebfre = lebfre[lebfre['age'].isna()]\n",
    "index_temp = lebfre.index.to_numpy()\n",
    "for i in index_temp:\n",
    "    df.at[i,'age'] = child_mean\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "#jhonston\n",
    "#parents\n",
    "df.at[783, 'age'] = male_mean\n",
    "df.at[924, 'age'] = female_mean\n",
    "df.at[888,'age'] = child_mean\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "df.at[1024, 'age'] = male_mean # has no sibsp as I looked\n",
    "df.at[128, 'age'] = child_mean\n",
    "df.at[593, 'age'] = child_mean\n",
    "df.at[166, 'age'] = female_mean\n",
    "df.at[533, 'age'] = female_mean\n",
    "df.at[593, 'age'] = female_mean\n",
    "df.at[1116, 'age'] = female_mean\n",
    "df.at[140, 'age'] = female_mean\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d36061d",
   "metadata": {},
   "source": [
    "## other nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "56607182",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fill fare nan as the average of 3 class . \n",
    "\n",
    "t_class = df[df['pclass'] == 3]\n",
    "t_class_mean = t_class['fare'].mean()\n",
    "df.at[1043, 'fare'] = t_class_mean\n",
    "\n",
    "# fill nan embarked to be an class of itself\n",
    "df.at[61, 'embarked'] = 'M'\n",
    "df.at[829, 'embarked'] = 'M'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f53e4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "title, last_name = parse_name(df) # parse names and fill name as last name to categorize it \n",
    "df['name'] = last_name \n",
    "df['cabin'] = df['cabin'].fillna(5) # all the nans in cabin are a caegory 5 \n",
    "df = cat_to_numeric(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ec614e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   passengerid  1309 non-null   int64  \n",
      " 1   survived     891 non-null    float64\n",
      " 2   pclass       1309 non-null   int64  \n",
      " 3   name         1309 non-null   int64  \n",
      " 4   sex          1309 non-null   int64  \n",
      " 5   age          1309 non-null   float64\n",
      " 6   sibsp        1309 non-null   int64  \n",
      " 7   parch        1309 non-null   int64  \n",
      " 8   ticket       1309 non-null   int64  \n",
      " 9   fare         1309 non-null   float64\n",
      " 10  cabin        1309 non-null   int64  \n",
      " 11  embarked     1309 non-null   int64  \n",
      "dtypes: float64(3), int64(9)\n",
      "memory usage: 122.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "29623f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(columns=['cabin', 'name', 'ticket']) # for now drop cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3c53368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide back into train test sets \n",
    "df_train = df.iloc[:890,:]\n",
    "df_test = df.iloc[891:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ba63b996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived       1.000000\n",
       "sex            0.543053\n",
       "cabin          0.270225\n",
       "fare           0.256995\n",
       "embarked       0.120736\n",
       "parch          0.081248\n",
       "name           0.019045\n",
       "passengerid   -0.003479\n",
       "sibsp         -0.035760\n",
       "ticket        -0.045727\n",
       "age           -0.065915\n",
       "pclass        -0.337996\n",
       "Name: survived, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_mat = df_train.corr()\n",
    "corr_mat['survived'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9dbb36",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ff2a974f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 890 entries, 0 to 889\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pclass    890 non-null    int64  \n",
      " 1   name      890 non-null    int64  \n",
      " 2   sex       890 non-null    int64  \n",
      " 3   age       890 non-null    float64\n",
      " 4   sibsp     890 non-null    int64  \n",
      " 5   parch     890 non-null    int64  \n",
      " 6   ticket    890 non-null    int64  \n",
      " 7   fare      890 non-null    float64\n",
      " 8   cabin     890 non-null    int64  \n",
      " 9   embarked  890 non-null    int64  \n",
      "dtypes: float64(2), int64(8)\n",
      "memory usage: 69.7 KB\n"
     ]
    }
   ],
   "source": [
    "x_train = df_train.drop(columns = ['survived', 'passengerid'])\n",
    "y_train = df_train['survived']\n",
    "x_train.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5186880",
   "metadata": {},
   "source": [
    "# scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0b32dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "x_test = df_test.drop(columns =  ['survived', 'passengerid'])\n",
    "x_test = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7637112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf\n",
    "clf = RandomForestClassifier(n_estimators= 100, max_depth=2, random_state=9)\n",
    "clf.fit(x_train, y_train)\n",
    "y_train_pred = clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a7ea79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=9, max_iter=500, solver = 'newton-cg') \n",
    "clf.fit(x_train, y_train)\n",
    "y_train_pred = clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "041e51c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "clf.fit(x_train, y_train)\n",
    "y_train_pred = clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2787ae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(gamma='auto')\n",
    "clf.fit(x_train, y_train)\n",
    "y_train_pred = clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cc8fcef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.846\n",
      "precision : 0.836\n",
      "recall : 0.746\n",
      "f_score : 0.788\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f_1, support = precision_recall_fscore_support(y_train, y_train_pred, average='binary')\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print('accuracy :', np.round(accuracy,3))\n",
    "print('precision :', np.round(precision,3))\n",
    "print('recall :', np.round(recall,3))\n",
    "print('f_score :', np.round(f_1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee19c12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_avg_accuracy : 0.825\n",
      "cv_avg_precision 0.812\n",
      "cv_avg_recall 0.716\n",
      "cv_avg_fscore : 0.757\n"
     ]
    }
   ],
   "source": [
    "cv_3_accuracy = cross_val_score(clf, x_train , y_train, cv=3, scoring='accuracy')\n",
    "cv_3_precision = cross_val_score(clf, x_train , y_train, cv=3, scoring='precision')\n",
    "cv_3_recall = cross_val_score(clf, x_train , y_train, cv=3, scoring='recall')\n",
    "cv_3_f1 = cross_val_score(clf, x_train , y_train, cv=3, scoring='f1')\n",
    "\n",
    "print('cv_avg_accuracy :', np.round(cv_3_accuracy.mean(),3))\n",
    "print('cv_avg_precision', np.round(cv_3_precision.mean(),3))\n",
    "print('cv_avg_recall', np.round(cv_3_recall.mean(),3))\n",
    "print('cv_avg_fscore :', np.round(cv_3_f1.mean(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6445bcab",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da16b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(x_test)\n",
    "y_test_pred = y_test_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5af55a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_id = df_test['passengerid'].values\n",
    "submission_df = pd.DataFrame({'Passengerid': passenger_id, 'Survived': y_test_pred})\n",
    "submission_df.to_csv('titanic_pred_2.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e353f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
