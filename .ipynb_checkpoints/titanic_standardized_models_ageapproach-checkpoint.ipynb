{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "04730771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import sys\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "import xgboost\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# import pre-processing modules \n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel \n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "# import classifiers\n",
    "# scale robust\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# scale sensitive\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# import evaluation modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d38ac8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(r\"C:/Users/Yehonatan/PycharmProject/DS/projects/titanic/ignore/test.csv\")\n",
    "train_set = pd.read_csv(r\"C:/Users/Yehonatan/PycharmProject/DS/projects/titanic/ignore/train.csv\")\n",
    "df_original = pd.concat([train_set,test_set], axis=0, ignore_index=True )\n",
    "\n",
    "df_train = (train_set.copy()).rename(columns=str.lower)\n",
    "df_test = (test_set.copy()).rename(columns=str.lower)\n",
    "\n",
    "df = (df_original.copy()).rename(columns=str.lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "de9059f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse title and fam name from df \n",
    "def parse_name(df):\n",
    "    last_name = df['name'].apply(lambda x : x.split(', ')[0])\n",
    "    temp = df['name'].apply(lambda x : x.split(', ')[1])\n",
    "    title = temp.apply(lambda x : x.split('.')[0])\n",
    "    return title, last_name\n",
    "\n",
    "def cat_to_numeric(df):\n",
    "    cat_columns = df.select_dtypes(['object']).columns\n",
    "    df[cat_columns] = df[cat_columns].apply(lambda x: pd.factorize(x)[0])\n",
    "    return df \n",
    "\n",
    "def pvalue_filter(target_df, features_df, alpha): # returns a list of columns that are possible drop, p_val > alpha, corr, pval\n",
    "    features_columns_names = list(features_df)\n",
    "    target_column_name = list(target_df)\n",
    "    features_np = features_df.to_numpy()\n",
    "    target_np = target_df.to_numpy()\n",
    "    drop_index = []\n",
    "    p_val_list =[]\n",
    "    corr_list = []\n",
    "    \n",
    "    for i in range(len(features_columns_names)):\n",
    "        corr, p_val = sp.stats.pearsonr(features_np[:,i], target_np)\n",
    "        corr_list.append(round(corr,3))\n",
    "        if p_val > alpha:           # accept the null hypothesis, no statisitcal significance  \n",
    "            drop_index.append(i)\n",
    "            p_val_list.append(p_val)\n",
    "            \n",
    "    drop_col = [features_columns_names[i] for i in drop_index]\n",
    "    return drop_col, corr_list, p_val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ef288aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df  age nans 263\n"
     ]
    }
   ],
   "source": [
    "# work on df nan and then concat with original df_train and sort by ID\n",
    "age_nan = df[df['age'].isna()]\n",
    "#age_nan.info()\n",
    "#age_nan = age_nan.sort_values(by=['sex'],ascending=True)\n",
    "#age_nan = age_nan.sort_values(by=['sibsp'],ascending=False).reset_index(drop=True)\n",
    "print('df  age nans',df['age'].isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6b8464",
   "metadata": {},
   "source": [
    "## deal with age nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "acc5daee",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Deal with masters  ############################################\n",
    "title, last_name = parse_name(age_nan)\n",
    "title = title[title == 'Master']\n",
    "master_index = title.index.to_numpy()\n",
    "\n",
    "df_young = df[df[\"age\"] < 15 ]\n",
    "child_mean = round(df_young['age'].mean(),2)\n",
    "       \n",
    "for i in master_index:\n",
    "    df.at[i,'age'] = child_mean \n",
    "\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "####### DEAL  with lone passengers ############################################\n",
    "\n",
    "l_p_t = age_nan[age_nan['sibsp'] == 0]\n",
    "lone_pass = l_p_t[l_p_t['parch'] == 0] # passengers who travel alone and cant determine their age by relatives\n",
    "#lone_pass\n",
    "\n",
    "# calc mean by gender\n",
    "df_male = df[df['sex'] == 'male']\n",
    "df_female = df[df['sex'] == 'female']\n",
    "male_mean = round(df_male['age'].mean(),2)\n",
    "female_mean = round(df_female['age'].mean(),2)\n",
    "\n",
    "lone_pass_male = lone_pass[lone_pass['sex'] == 'male']\n",
    "lone_pass_female = lone_pass[lone_pass['sex'] == 'female']\n",
    "\n",
    "l_p_m_index = (lone_pass_male.index).to_numpy()\n",
    "l_p_f_index = (lone_pass_female.index).to_numpy()\n",
    "\n",
    "for m in l_p_m_index:\n",
    "    df.at[m,'age'] = male_mean\n",
    "\n",
    "for f in l_p_f_index:\n",
    "    df.at[f,'age'] = female_mean\n",
    "    \n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "\n",
    "\n",
    "########## ONE companion ############################################################\n",
    "# one companion in nan df # assign the age of the companion tot the nan \n",
    "one_comp_nan = age_nan[age_nan['parch'] == 0] \n",
    "one_comp_nan = one_comp_nan[one_comp_nan['sibsp'] == 1]\n",
    "title_ocn, last_name_ocn = parse_name(one_comp_nan)\n",
    "ocn_index = (title_ocn.index).to_numpy()\n",
    "\n",
    "\n",
    "one_comp = df[df['parch'] == 0] # one companion in general df may contain istself. but some companions are both nan in age\n",
    "one_comp = one_comp[one_comp['sibsp'] == 1]\n",
    "#one_comp = one_comp[~one_comp['age'].isna()]\n",
    "title_oc, last_name_oc = parse_name(one_comp)\n",
    "oc_index = (title_oc.index).to_numpy()\n",
    "\n",
    "for l in range(len(one_comp_nan)):\n",
    "    for i in range(len(one_comp)):\n",
    "        \n",
    "        if (list(last_name_ocn)[l] == list(last_name_oc)[i] and ocn_index[l] != oc_index[i]): #ensures same last name and not same person\n",
    "        \n",
    "            if df.at[oc_index[i],'age'] != float('nan'):\n",
    "                df.at[ocn_index[l],'age'] =  df.at[oc_index[i],'age'] \n",
    "            if list(title_ocn)[l] == 'Mrs' : # she and her husbnad are adults and get the adult average\n",
    "                df.at[ocn_index[l],'age'] = female_mean\n",
    "                df.at[oc_index[i],'age'] = male_mean\n",
    "            if list(title_ocn)[l] == 'Miss': # she is a miss and I assume that travels with a sibling so get young average\n",
    "                df.at[ocn_index[l],'age'] = child_mean\n",
    "                df.at[oc_index[i],'age'] = child_mean\n",
    "            if list(title_ocn)[l] == 'Mr' and list(title_oc)[i] != 'Mrs':\n",
    "                df.at[ocn_index[l],'age'] = child_mean\n",
    "                df.at[oc_index[i],'age'] = child_mean\n",
    "\n",
    "\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "# notice there are only two famillies with 3 siblings travelling together I assume they are all young <15.\n",
    "three_siblings = age_nan[age_nan['parch'] == 0] \n",
    "three_siblings = three_siblings[three_siblings['sibsp'] == 2]\n",
    "index_temp = three_siblings.index.to_numpy()\n",
    "for i in index_temp:\n",
    "    df.at[i,'age'] = child_mean\n",
    "\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "########### Hand fill age nans #######################################################\n",
    "\n",
    "\n",
    "# hand fill, thought it will be quicker than thinking about an algo  \n",
    "#parents\n",
    "df.at[1233, 'age'] = male_mean\n",
    "df.at[1256, 'age'] = female_mean\n",
    "#kids\n",
    "sages = df[df['ticket'] == 'CA. 2343']\n",
    "sages = sages[sages['age'].isna()]\n",
    "\n",
    "index_temp = sages.index.to_numpy()\n",
    "for i in index_temp:\n",
    "    df.at[i,'age'] = child_mean\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "df.at[1023, 'age'] = female_mean\n",
    "lebfre = df[df['ticket'] == '4133']\n",
    "lebfre = lebfre[lebfre['age'].isna()]\n",
    "index_temp = lebfre.index.to_numpy()\n",
    "for i in index_temp:\n",
    "    df.at[i,'age'] = child_mean\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "#jhonston\n",
    "#parents\n",
    "df.at[783, 'age'] = male_mean\n",
    "df.at[924, 'age'] = female_mean\n",
    "df.at[888,'age'] = child_mean\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "df.at[1024, 'age'] = male_mean # has no sibsp as I looked\n",
    "df.at[128, 'age'] = child_mean\n",
    "df.at[593, 'age'] = child_mean\n",
    "df.at[166, 'age'] = female_mean\n",
    "df.at[533, 'age'] = female_mean\n",
    "df.at[593, 'age'] = female_mean\n",
    "df.at[1116, 'age'] = female_mean\n",
    "df.at[140, 'age'] = female_mean\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d36061d",
   "metadata": {},
   "source": [
    "## other nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "56607182",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fill fare nan as the average of 3 class . \n",
    "\n",
    "t_class = df[df['pclass'] == 3]\n",
    "t_class_mean = t_class['fare'].mean()\n",
    "df.at[1043, 'fare'] = t_class_mean\n",
    "\n",
    "# fill nan embarked to be an class of itself\n",
    "df.at[61, 'embarked'] = 'M'\n",
    "df.at[829, 'embarked'] = 'M'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f53e4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "title, last_name = parse_name(df) # parse names and fill name as last name to categorize it \n",
    "df['name'] = last_name \n",
    "df['cabin'] = df['cabin'].fillna(5) # all the nans in cabin are a caegory 5 \n",
    "\n",
    "df = cat_to_numeric(df)\n",
    "\n",
    "survived = df['survived']\n",
    "passenger_id = df['passengerid'].values\n",
    "\n",
    "df = df.drop(columns=['survived','passengerid','name', 'sibsp', 'ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ec614e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pclass    1309 non-null   int64  \n",
      " 1   sex       1309 non-null   int64  \n",
      " 2   age       1309 non-null   float64\n",
      " 3   parch     1309 non-null   int64  \n",
      " 4   fare      1309 non-null   float64\n",
      " 5   cabin     1309 non-null   int64  \n",
      " 6   embarked  1309 non-null   int64  \n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 71.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "29623f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(columns=['cabin', 'name', 'ticket']) # for now drop cabin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c258221b",
   "metadata": {},
   "source": [
    "# scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "359a2ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns_selector = selector(dtype_exclude=int)\n",
    "categorical_columns_selector = selector(dtype_include=int)\n",
    "\n",
    "numerical_columns = numerical_columns_selector(df)\n",
    "categorical_columns = categorical_columns_selector(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d843f7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'fare']\n",
      "['pclass', 'sex', 'parch', 'cabin', 'embarked']\n"
     ]
    }
   ],
   "source": [
    "print(numerical_columns)\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "425c5947",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "numerical_preprocessor = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "02600945",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "    ('standard_scaler', numerical_preprocessor, numerical_columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "89e320c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(preprocessor, SVC(kernel='rbf') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "50628101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide back into train test sets \n",
    "df_train = df.iloc[:890,:]\n",
    "df_test = df.iloc[891:,:]\n",
    "\n",
    "x_train = df_train\n",
    "y_train = survived.iloc[:890]\n",
    "\n",
    "\n",
    "x_test = df_test\n",
    "y_test = survived.iloc[891:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6437c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(x_train, y_train)\n",
    "y_train_pred = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d320225",
   "metadata": {},
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7637112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rf\n",
    "# clf = LogisticRegression(random_state=9, max_iter=500, solver = 'newton-cg') \n",
    "# clf = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "# clf = SVC(kernel='poly')\n",
    "# clf = KNeighborsClassifier()\n",
    "# clf = GradientBoostingClassifier(n_estimators=40, learning_rate=0.2,max_depth=2, random_state=0)\n",
    "# clf = LinearSVC(random_state=0, tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cc8fcef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.842\n",
      "precision : 0.907\n",
      "recall : 0.655\n",
      "f_score : 0.761\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f_1, support = precision_recall_fscore_support(y_train, y_train_pred, average='binary')\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print('accuracy :', np.round(accuracy,3))\n",
    "print('precision :', np.round(precision,3))\n",
    "print('recall :', np.round(recall,3))\n",
    "print('f_score :', np.round(f_1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ee19c12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_avg_accuracy : 0.813\n",
      "cv_avg_precision 0.829\n",
      "cv_avg_recall 0.652\n",
      "cv_avg_fscore : 0.728\n"
     ]
    }
   ],
   "source": [
    "cv_3_accuracy = cross_val_score(model, x_train , y_train, cv=3, scoring='accuracy')\n",
    "cv_3_precision = cross_val_score(model, x_train , y_train, cv=3, scoring='precision')\n",
    "cv_3_recall = cross_val_score(model, x_train , y_train, cv=3, scoring='recall')\n",
    "cv_3_f1 = cross_val_score(model, x_train , y_train, cv=3, scoring='f1')\n",
    "\n",
    "print('cv_avg_accuracy :', np.round(cv_3_accuracy.mean(),3))\n",
    "print('cv_avg_precision', np.round(cv_3_precision.mean(),3))\n",
    "print('cv_avg_recall', np.round(cv_3_recall.mean(),3))\n",
    "print('cv_avg_fscore :', np.round(cv_3_f1.mean(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6445bcab",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da16b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred = y_test_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5af55a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission_df = pd.DataFrame({'Passengerid': passenger_id[891:], 'Survived': y_test_pred})\n",
    "submission_df.to_csv('titanic_pred_9.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e353f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
