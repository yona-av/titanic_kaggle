{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "989400a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yehonatan\\AppData\\Local\\Temp\\ipykernel_12012\\132814144.py:27: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-notebook')\n"
     ]
    }
   ],
   "source": [
    "# Import our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Import sklearn libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve, auc, make_scorer, confusion_matrix, f1_score, fbeta_score\n",
    "\n",
    "# Import the Naive Bayes, logistic regression, Bagging, RandomForest, AdaBoost, GradientBoost, Decision Trees and SVM Classifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from matplotlib import style\n",
    "#plt.style.use('bmh')\n",
    "#plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-notebook')\n",
    "\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelBinarizer\n",
    "\n",
    "# import evaluation modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07530877",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(r\"C:/Users/Yehonatan/PycharmProject/DS/projects/titanic/ignore/test.csv\")\n",
    "train_df = pd.read_csv(r\"C:/Users/Yehonatan/PycharmProject/DS/projects/titanic/ignore/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8407a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes    537\n",
       "No     354\n",
       "Name: travelled_alone, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n",
    "    dataset.loc[dataset['relatives'] > 0, 'travelled_alone'] = 'No'\n",
    "    dataset.loc[dataset['relatives'] == 0, 'travelled_alone'] = 'Yes'\n",
    "    #dataset['travelled_alone'] = dataset['travelled_alone'].astype(int)\n",
    "train_df['travelled_alone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f7b805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'PassengerId' from the train set, because it does not contribute to a persons survival probability.\n",
    "train_df = train_df.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "553c3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "deck = {\"A\": \"A\", \"B\": \"B\", \"C\": \"C\", \"D\": \"D\", \"E\": \"E\", \"F\": \"F\", \"G\": \"G\", \"U\": \"U\"}\n",
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Cabin'] = dataset['Cabin'].fillna(\"U0\")\n",
    "    dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n",
    "    dataset['Deck'] = dataset['Deck'].map(deck)\n",
    "    dataset['Deck'] = dataset['Deck'].fillna(\"U\")\n",
    "    #dataset['Deck'] = dataset['Deck'].astype(int)\n",
    "# we can now drop the cabin feature\n",
    "train_df = train_df.drop(['Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea591475",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    mean = train_df[\"Age\"].mean()\n",
    "    std = test_df[\"Age\"].std()\n",
    "    is_null = dataset[\"Age\"].isnull().sum()\n",
    "    # compute random numbers between the mean, std and is_null\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
    "    # fill NaN values in Age column with random values generated\n",
    "    age_slice = dataset[\"Age\"].copy()\n",
    "    age_slice[np.isnan(age_slice)] = rand_age\n",
    "    dataset[\"Age\"] = age_slice\n",
    "    dataset[\"Age\"] = train_df[\"Age\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be4eb72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Age\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33a85835",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_value = 'S'\n",
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(common_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "611c598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(0)\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e9ffd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Fare'] = train_df['Fare'].astype(int)\n",
    "test_df['Fare'] = test_df['Fare'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc9cf0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_titles = train_df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "type(train_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "894d9e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "titles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "\n",
    "for dataset in data:\n",
    "    # extract titles\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    # replace titles with a more common title or as Rare\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n",
    "                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    # convert titles into numbers\n",
    "    #dataset['Title'] = dataset['Title'].map(titles)\n",
    "    # filling NaN with 0, to get safe\n",
    "    dataset['Title'] = dataset['Title'].fillna(\"NA\")\n",
    "train_df = train_df.drop(['Name'], axis=1)\n",
    "test_df = test_df.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17898db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Ticket'], axis=1)\n",
    "test_df = test_df.drop(['Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce80143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset['Age_Class']= dataset['Age']* dataset['Pclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ba3dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in data:\n",
    "    dataset['Fare_Per_Person'] = dataset['Fare']/(dataset['relatives']+1)\n",
    "    dataset['Fare_Per_Person'] = dataset['Fare_Per_Person'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efff1774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adults          167\n",
       "Senior          154\n",
       "Middle Age      148\n",
       "Young Adults    135\n",
       "Youngsters      113\n",
       "Teens            99\n",
       "Children         68\n",
       "Retired           7\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n",
    "    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n",
    "    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n",
    "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n",
    "    dataset.loc[ dataset['Age'] > 66, 'Age'] = 7\n",
    "    \n",
    "    dataset['Age'] = dataset['Age'].astype(str)\n",
    "    dataset.loc[ dataset['Age'] == '0', 'Age'] = \"Children\"\n",
    "    dataset.loc[ dataset['Age'] == '1', 'Age'] = \"Teens\"\n",
    "    dataset.loc[ dataset['Age'] == '2', 'Age'] = \"Youngsters\"\n",
    "    dataset.loc[ dataset['Age'] == '3', 'Age'] = \"Young Adults\"\n",
    "    dataset.loc[ dataset['Age'] == '4', 'Age'] = \"Adults\"\n",
    "    dataset.loc[ dataset['Age'] == '5', 'Age'] = \"Middle Age\"\n",
    "    dataset.loc[ dataset['Age'] == '6', 'Age'] = \"Senior\"\n",
    "    dataset.loc[ dataset['Age'] == '7', 'Age'] = \"Retired\"\n",
    "\n",
    "# let's see how it's distributed \n",
    "train_df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a41c63cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[(dataset['Fare'] > 31) & (dataset['Fare'] <= 99), 'Fare']   = 3\n",
    "    dataset.loc[(dataset['Fare'] > 99) & (dataset['Fare'] <= 250), 'Fare']   = 4\n",
    "    dataset.loc[ dataset['Fare'] > 250, 'Fare'] = 5\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    dataset['Fare'] = dataset['Fare'].astype(str)\n",
    "    dataset.loc[ dataset['Fare'] == '0', 'Fare'] = \"Extremely Low\"\n",
    "    dataset.loc[ dataset['Fare'] == '1', 'Fare'] = \"Very Low\"\n",
    "    dataset.loc[ dataset['Fare'] == '2', 'Fare'] = \"Low\"\n",
    "    dataset.loc[ dataset['Fare'] == '3', 'Fare'] = \"High\"\n",
    "    dataset.loc[ dataset['Fare'] == '4', 'Fare'] = \"Very High\"\n",
    "    dataset.loc[ dataset['Fare'] == '5', 'Fare'] = \"Extremely High\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "515da589",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Pclass'] = dataset['Pclass'].astype(str)\n",
    "    dataset.loc[ dataset['Pclass'] == '1', 'Pclass'] = \"Class1\"\n",
    "    dataset.loc[ dataset['Pclass'] == '2', 'Pclass'] = \"Class2\"\n",
    "    dataset.loc[ dataset['Pclass'] == '3', 'Pclass'] = \"Class3\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7a9b047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Survived', 'SibSp', 'Parch', 'relatives', 'Age_Class', 'Fare_Per_Person']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capture all the numerical features so that we can scale them later\n",
    "#data = [train_df, test_df]\n",
    "train_numerical_features = list(train_df.select_dtypes(include=['int64', 'float64', 'int32']).columns)\n",
    "train_numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb629bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SibSp', 'Parch', 'relatives', 'Age_Class', 'Fare_Per_Person']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_numerical_features[0]\n",
    "train_numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d028b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling - Standard scaler\n",
    "ss_scaler = StandardScaler()\n",
    "train_df_ss = pd.DataFrame(data = train_df)\n",
    "train_df_ss[train_numerical_features] = ss_scaler.fit_transform(train_df_ss[train_numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af6db458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>relatives</th>\n",
       "      <th>travelled_alone</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Title</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>Fare_Per_Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Class3</td>\n",
       "      <td>male</td>\n",
       "      <td>Youngsters</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>Extremely Low</td>\n",
       "      <td>S</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>No</td>\n",
       "      <td>U</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0.048760</td>\n",
       "      <td>-0.459218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Class1</td>\n",
       "      <td>female</td>\n",
       "      <td>Middle Age</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>High</td>\n",
       "      <td>C</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>No</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>-0.776518</td>\n",
       "      <td>0.434090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Class3</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adults</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>Extremely Low</td>\n",
       "      <td>S</td>\n",
       "      <td>-0.560975</td>\n",
       "      <td>Yes</td>\n",
       "      <td>U</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0.402450</td>\n",
       "      <td>-0.347554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Class1</td>\n",
       "      <td>female</td>\n",
       "      <td>Middle Age</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>High</td>\n",
       "      <td>S</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>No</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>-0.864940</td>\n",
       "      <td>0.182847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Class3</td>\n",
       "      <td>male</td>\n",
       "      <td>Middle Age</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>Very Low</td>\n",
       "      <td>S</td>\n",
       "      <td>-0.560975</td>\n",
       "      <td>Yes</td>\n",
       "      <td>U</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1.198253</td>\n",
       "      <td>-0.319638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex           Age     SibSp     Parch           Fare  \\\n",
       "0         0  Class3    male    Youngsters  0.432793 -0.473674  Extremely Low   \n",
       "1         1  Class1  female    Middle Age  0.432793 -0.473674           High   \n",
       "2         1  Class3  female  Young Adults -0.474545 -0.473674  Extremely Low   \n",
       "3         1  Class1  female    Middle Age  0.432793 -0.473674           High   \n",
       "4         0  Class3    male    Middle Age -0.474545 -0.473674       Very Low   \n",
       "\n",
       "  Embarked  relatives travelled_alone Deck Title  Age_Class  Fare_Per_Person  \n",
       "0        S   0.059160              No    U    Mr   0.048760        -0.459218  \n",
       "1        C   0.059160              No    C   Mrs  -0.776518         0.434090  \n",
       "2        S  -0.560975             Yes    U  Miss   0.402450        -0.347554  \n",
       "3        S   0.059160              No    C   Mrs  -0.864940         0.182847  \n",
       "4        S  -0.560975             Yes    U    Mr   1.198253        -0.319638  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_ss.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b69824c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId', 'SibSp', 'Parch', 'relatives', 'Age_Class', 'Fare_Per_Person']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_numerical_features = list(test_df.select_dtypes(include=['int64', 'float64', 'int32']).columns)\n",
    "test_numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24736668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SibSp', 'Parch', 'relatives', 'Age_Class', 'Fare_Per_Person']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test_numerical_features[0]\n",
    "test_numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e1397aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling - Standard scaler\n",
    "test_ss_scaler = StandardScaler()\n",
    "test_df_ss = pd.DataFrame(data = test_df)\n",
    "test_df_ss[test_numerical_features] = test_ss_scaler.fit_transform(test_df_ss[test_numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54e21c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot encoding / Dummy variables\n",
    "encode_col_list = list(train_df.select_dtypes(include=['object']).columns)\n",
    "for i in encode_col_list:\n",
    "    train_df_ss = pd.concat([train_df_ss,pd.get_dummies(train_df_ss[i], prefix=i)],axis=1)\n",
    "    train_df_ss.drop(i, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6df88082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot encoding / Dummy variables\n",
    "test_encode_col_list = list(test_df.select_dtypes(include=['object']).columns)\n",
    "for i in test_encode_col_list:\n",
    "    test_df_ss = pd.concat([test_df_ss,pd.get_dummies(test_df_ss[i], prefix=i)],axis=1)\n",
    "    test_df_ss.drop(i, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9984a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df_ss.drop(\"Survived\", axis=1)\n",
    "Y_train = train_df_ss[\"Survived\"]\n",
    "X_test  = test_df_ss.drop(\"PassengerId\", axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5e64e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf =  XGBClassifier(n_estimators=100, max_depth=5 ,learning_rate=0.5, objective='binary:logistic',gamma=3)\n",
    "clf.fit(X_train, Y_train)\n",
    "y_train_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "94ea7deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=9, max_iter=500, solver = 'newton-cg') \n",
    "clf.fit(X_train, Y_train)\n",
    "y_train_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0728cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_train_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7fa44b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.875\n",
      "precision : 0.874\n",
      "recall : 0.789\n",
      "f_score : 0.829\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f_1, support = precision_recall_fscore_support(Y_train, y_train_pred, average='binary')\n",
    "accuracy = accuracy_score(Y_train, y_train_pred)\n",
    "print('accuracy :', np.round(accuracy,3))\n",
    "print('precision :', np.round(precision,3))\n",
    "print('recall :', np.round(recall,3))\n",
    "print('f_score :', np.round(f_1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "726ca65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_avg_accuracy : 0.837\n",
      "cv_avg_precision 0.823\n",
      "cv_avg_recall 0.737\n",
      "cv_avg_fscore : 0.775\n"
     ]
    }
   ],
   "source": [
    "cv_5_accuracy = cross_val_score(clf, X_train , Y_train, cv=5, scoring='accuracy')\n",
    "cv_5_precision = cross_val_score(clf, X_train , Y_train, cv=5, scoring='precision')\n",
    "cv_5_recall = cross_val_score(clf, X_train , Y_train, cv=5, scoring='recall')\n",
    "cv_5_f1 = cross_val_score(clf, X_train , Y_train, cv=5, scoring='f1')\n",
    "\n",
    "print('cv_avg_accuracy :', np.round(cv_5_accuracy.mean(),3))\n",
    "print('cv_avg_precision', np.round(cv_5_precision.mean(),3))\n",
    "print('cv_avg_recall', np.round(cv_5_recall.mean(),3))\n",
    "print('cv_avg_fscore :', np.round(cv_5_f1.mean(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "06ae0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_predictions = clf.predict(X_test)\n",
    "\n",
    "logreg_data = pd.read_csv(r\"C:/Users/Yehonatan/PycharmProject/DS/projects/titanic/ignore/test.csv\")\n",
    "logreg_data.insert((logreg_data.shape[1]),'Survived',logreg_predictions)\n",
    "\n",
    "logreg_data.to_csv('xgb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8890a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
