{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04730771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import sys\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "import xgboost\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# import pre-processing modules \n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel \n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "# import classifiers\n",
    "# scale robust\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# scale sensitive\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# import evaluation modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support, classification_report\n",
    "from sklearn.metrics import  RocCurveDisplay, roc_auc_score, auc, roc_curve, PrecisionRecallDisplay, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d38ac8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(r\"C:/Users/Yehonatan/PycharmProject/DS/projects/titanic/ignore/test.csv\")\n",
    "train_set = pd.read_csv(r\"C:/Users/Yehonatan/PycharmProject/DS/projects/titanic/ignore/train.csv\")\n",
    "df_original = pd.concat([train_set,test_set], axis=0, ignore_index=True )\n",
    "\n",
    "df_train = (train_set.copy()).rename(columns=str.lower)\n",
    "df_test = (test_set.copy()).rename(columns=str.lower)\n",
    "\n",
    "df = (df_original.copy()).rename(columns=str.lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de9059f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse title and fam name from df \n",
    "def parse_name(df):\n",
    "    last_name = df['name'].apply(lambda x : x.split(', ')[0])\n",
    "    temp = df['name'].apply(lambda x : x.split(', ')[1])\n",
    "    title = temp.apply(lambda x : x.split('.')[0])\n",
    "    return title, last_name\n",
    "\n",
    "def cat_to_numeric(df):\n",
    "    cat_columns = df.select_dtypes(['object']).columns\n",
    "    df[cat_columns] = df[cat_columns].apply(lambda x: pd.factorize(x)[0])\n",
    "    return df \n",
    "\n",
    "def pvalue_filter(target_df, features_df, alpha): # returns a list of columns that are possible drop, p_val > alpha, corr, pval\n",
    "    features_columns_names = list(features_df)\n",
    "    target_column_name = list(target_df)\n",
    "    features_np = features_df.to_numpy()\n",
    "    target_np = target_df.to_numpy()\n",
    "    drop_index = []\n",
    "    p_val_list =[]\n",
    "    corr_list = []\n",
    "    \n",
    "    for i in range(len(features_columns_names)):\n",
    "        corr, p_val = sp.stats.pearsonr(features_np[:,i], target_np)\n",
    "        corr_list.append(round(corr,3))\n",
    "        if p_val > alpha:           # accept the null hypothesis, no statisitcal significance  \n",
    "            drop_index.append(i)\n",
    "            p_val_list.append(p_val)\n",
    "            \n",
    "    drop_col = [features_columns_names[i] for i in drop_index]\n",
    "    return drop_col, corr_list, p_val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef288aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df  age nans 263\n"
     ]
    }
   ],
   "source": [
    "# work on df nan and then concat with original df_train and sort by ID\n",
    "age_nan = df[df['age'].isna()]\n",
    "#age_nan.info()\n",
    "#age_nan = age_nan.sort_values(by=['sex'],ascending=True)\n",
    "#age_nan = age_nan.sort_values(by=['sibsp'],ascending=False).reset_index(drop=True)\n",
    "print('df  age nans',df['age'].isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6b8464",
   "metadata": {},
   "source": [
    "## deal with age nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acc5daee",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Deal with masters  ############################################\n",
    "title, last_name = parse_name(age_nan)\n",
    "title = title[title == 'Master']\n",
    "master_index = title.index.to_numpy()\n",
    "\n",
    "df_young = df[df[\"age\"] < 15 ]\n",
    "child_mean = round(df_young['age'].mean(),2)\n",
    "       \n",
    "for i in master_index:\n",
    "    df.at[i,'age'] = child_mean \n",
    "\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "####### DEAL  with lone passengers ############################################\n",
    "\n",
    "l_p_t = age_nan[age_nan['sibsp'] == 0]\n",
    "lone_pass = l_p_t[l_p_t['parch'] == 0] # passengers who travel alone and cant determine their age by relatives\n",
    "#lone_pass\n",
    "\n",
    "# calc mean by gender\n",
    "df_male = df[df['sex'] == 'male']\n",
    "df_female = df[df['sex'] == 'female']\n",
    "male_mean = round(df_male['age'].mean(),2)\n",
    "female_mean = round(df_female['age'].mean(),2)\n",
    "\n",
    "lone_pass_male = lone_pass[lone_pass['sex'] == 'male']\n",
    "lone_pass_female = lone_pass[lone_pass['sex'] == 'female']\n",
    "\n",
    "l_p_m_index = (lone_pass_male.index).to_numpy()\n",
    "l_p_f_index = (lone_pass_female.index).to_numpy()\n",
    "\n",
    "for m in l_p_m_index:\n",
    "    df.at[m,'age'] = male_mean\n",
    "\n",
    "for f in l_p_f_index:\n",
    "    df.at[f,'age'] = female_mean\n",
    "    \n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "\n",
    "\n",
    "########## ONE companion ############################################################\n",
    "# one companion in nan df # assign the age of the companion tot the nan \n",
    "one_comp_nan = age_nan[age_nan['parch'] == 0] \n",
    "one_comp_nan = one_comp_nan[one_comp_nan['sibsp'] == 1]\n",
    "title_ocn, last_name_ocn = parse_name(one_comp_nan)\n",
    "ocn_index = (title_ocn.index).to_numpy()\n",
    "\n",
    "\n",
    "one_comp = df[df['parch'] == 0] # one companion in general df may contain istself. but some companions are both nan in age\n",
    "one_comp = one_comp[one_comp['sibsp'] == 1]\n",
    "#one_comp = one_comp[~one_comp['age'].isna()]\n",
    "title_oc, last_name_oc = parse_name(one_comp)\n",
    "oc_index = (title_oc.index).to_numpy()\n",
    "\n",
    "for l in range(len(one_comp_nan)):\n",
    "    for i in range(len(one_comp)):\n",
    "        \n",
    "        if (list(last_name_ocn)[l] == list(last_name_oc)[i] and ocn_index[l] != oc_index[i]): #ensures same last name and not same person\n",
    "        \n",
    "            if df.at[oc_index[i],'age'] != float('nan'):\n",
    "                df.at[ocn_index[l],'age'] =  df.at[oc_index[i],'age'] \n",
    "            if list(title_ocn)[l] == 'Mrs' : # she and her husbnad are adults and get the adult average\n",
    "                df.at[ocn_index[l],'age'] = female_mean\n",
    "                df.at[oc_index[i],'age'] = male_mean\n",
    "            if list(title_ocn)[l] == 'Miss': # she is a miss and I assume that travels with a sibling so get young average\n",
    "                df.at[ocn_index[l],'age'] = child_mean\n",
    "                df.at[oc_index[i],'age'] = child_mean\n",
    "            if list(title_ocn)[l] == 'Mr' and list(title_oc)[i] != 'Mrs':\n",
    "                df.at[ocn_index[l],'age'] = child_mean\n",
    "                df.at[oc_index[i],'age'] = child_mean\n",
    "\n",
    "\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "# notice there are only two famillies with 3 siblings travelling together I assume they are all young <15.\n",
    "three_siblings = age_nan[age_nan['parch'] == 0] \n",
    "three_siblings = three_siblings[three_siblings['sibsp'] == 2]\n",
    "index_temp = three_siblings.index.to_numpy()\n",
    "for i in index_temp:\n",
    "    df.at[i,'age'] = child_mean\n",
    "\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "########### Hand fill age nans #######################################################\n",
    "\n",
    "\n",
    "# hand fill, thought it will be quicker than thinking about an algo  \n",
    "#parents\n",
    "df.at[1233, 'age'] = male_mean\n",
    "df.at[1256, 'age'] = female_mean\n",
    "#kids\n",
    "sages = df[df['ticket'] == 'CA. 2343']\n",
    "sages = sages[sages['age'].isna()]\n",
    "\n",
    "index_temp = sages.index.to_numpy()\n",
    "for i in index_temp:\n",
    "    df.at[i,'age'] = child_mean\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "df.at[1023, 'age'] = female_mean\n",
    "lebfre = df[df['ticket'] == '4133']\n",
    "lebfre = lebfre[lebfre['age'].isna()]\n",
    "index_temp = lebfre.index.to_numpy()\n",
    "for i in index_temp:\n",
    "    df.at[i,'age'] = child_mean\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "#jhonston\n",
    "#parents\n",
    "df.at[783, 'age'] = male_mean\n",
    "df.at[924, 'age'] = female_mean\n",
    "df.at[888,'age'] = child_mean\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "df.at[1024, 'age'] = male_mean # has no sibsp as I looked\n",
    "df.at[128, 'age'] = child_mean\n",
    "df.at[593, 'age'] = child_mean\n",
    "df.at[166, 'age'] = female_mean\n",
    "df.at[533, 'age'] = female_mean\n",
    "df.at[593, 'age'] = female_mean\n",
    "df.at[1116, 'age'] = female_mean\n",
    "df.at[140, 'age'] = female_mean\n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4223954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df  cabin nans 1014\n",
      "df cabin nans updated 998\n",
      "df cabin nans updated 981\n",
      "df cabin nans updated 0\n"
     ]
    }
   ],
   "source": [
    "# deal with cabin nan by comparing the ticket number \n",
    "# small number of nans but I know for certain that they get the correct cabin\n",
    "cabin = df[~df['cabin'].isna()]\n",
    "cabin_nan =  df[df['cabin'].isna()]\n",
    "print('df  cabin nans',df['cabin'].isna().sum())\n",
    "\n",
    "for t in range(len(cabin['ticket'])):\n",
    "    for n in range(len(cabin_nan['ticket'])):\n",
    "        if cabin['ticket'].iloc[t] == cabin_nan['ticket'].iloc[n] :\n",
    "           \n",
    "            index = cabin['passengerid'].iloc[t] - 1    \n",
    "            index_nan = cabin_nan['passengerid'].iloc[n] - 1 \n",
    "            if index != index_nan:\n",
    "\n",
    "                # update the value of cabin_nan in the df\n",
    "                df.at[index_nan,'cabin'] = df.at[index,'cabin']\n",
    "\n",
    "\n",
    "\n",
    "cabin_nan =  df[df['cabin'].isna()] # update cabin_nan\n",
    "print('df cabin nans updated',len(cabin_nan))    \n",
    "\n",
    "\n",
    "# handle single men and single women in seconde and thied class \n",
    "\n",
    "s_t_class_cabin = cabin[cabin['pclass'] != 1] \n",
    "single_temp = s_t_class_cabin[s_t_class_cabin['sibsp'] == 0]\n",
    "single_cabin = single_temp[single_temp['parch'] == 0]\n",
    "\n",
    "s_t_class_cabin_female = single_cabin[single_cabin['sex'] == 'female'] # single 2 3 class female\n",
    "\n",
    "s_t_class_cabin_nan = cabin_nan[cabin_nan['pclass'] != 1]\n",
    "single_temp = s_t_class_cabin_nan[s_t_class_cabin_nan['sibsp'] == 0]\n",
    "single_cabin_nan = single_temp[single_temp['parch'] == 0]\n",
    "\n",
    "\n",
    "s_t_class_cabin_nan_female = single_cabin_nan[single_cabin_nan['sex'] == 'female']\n",
    "\n",
    "# deal with female. compare fare  \n",
    "#why separated - coz generlizing the cabin nan in male might be different   \n",
    "\n",
    "for t in range(len(s_t_class_cabin_female)):\n",
    "    for n in range(len(s_t_class_cabin_nan_female)):\n",
    "        if s_t_class_cabin_female['fare'].iloc[t] == s_t_class_cabin_nan_female['fare'].iloc[n] :\n",
    "            \n",
    "            pclass_cabin = s_t_class_cabin_female['pclass'].iloc[t]              \n",
    "            pclass_cabin_nan = s_t_class_cabin_nan_female['pclass'].iloc[n]\n",
    "            index = s_t_class_cabin_female['passengerid'].iloc[t] - 1    \n",
    "            index_nan = s_t_class_cabin_nan_female['passengerid'].iloc[n] - 1 \n",
    "            \n",
    "            if index != index_nan and pclass_cabin == pclass_cabin_nan : # make sure the deduction about cabin doesnt cross pclass\n",
    "\n",
    "                df.at[index_nan,'cabin'] = df.at[index,'cabin'] # update the value of cabin_nan in the df\n",
    "\n",
    "cabin_nan =  df[df['cabin'].isna()] \n",
    "print('df cabin nans updated',len(cabin_nan))    \n",
    "\n",
    "# deal with the rest \n",
    "\n",
    "for p in range(len(cabin_nan)):\n",
    "    \n",
    "    # third class\n",
    "    if cabin_nan['pclass'].iloc[p] == 3 and cabin_nan['sex'].iloc[p] == 'male':\n",
    "        index = cabin_nan['passengerid'].iloc[p] - 1\n",
    "        p = np.random.randint(low=1, high=101, size=1, dtype=int)[0]\n",
    "        if p <= 13:\n",
    "            df.at[index,'cabin'] = 'l'\n",
    "        elif p > 13:\n",
    "                df.at[index,'cabin'] = 'D'\n",
    "    \n",
    "    if cabin_nan['pclass'].iloc[p] == 3 and cabin_nan['sex'].iloc[p] == 'female':\n",
    "        index = cabin_nan['passengerid'].iloc[p] - 1\n",
    "        p = np.random.randint(low=1, high=101, size=1, dtype=int)[0]\n",
    "        if p < 50:\n",
    "            df.at[index,'cabin'] = 'l'\n",
    "        elif p >= 50:\n",
    "                df.at[index,'cabin'] = 'D'\n",
    "                \n",
    "    # second class\n",
    "    if cabin_nan['pclass'].iloc[p] == 2 and cabin_nan['sex'].iloc[p] == 'male':\n",
    "        index = cabin_nan['passengerid'].iloc[p] - 1\n",
    "        p = np.random.randint(low=1, high=101, size=1, dtype=int)[0]\n",
    "        if p <= 13:\n",
    "            df.at[index,'cabin'] = 'l'\n",
    "        elif p > 13:\n",
    "                df.at[index,'cabin'] = 'D'\n",
    "    \n",
    "    if cabin_nan['pclass'].iloc[p] == 2 and cabin_nan['sex'].iloc[p] == 'female':\n",
    "        index = cabin_nan['passengerid'].iloc[p] - 1\n",
    "        p = np.random.randint(low=1, high=101, size=1, dtype=int)[0]\n",
    "        if p <= 93:\n",
    "            df.at[index,'cabin'] = 'l'\n",
    "        elif p >= 93:\n",
    "                df.at[index,'cabin'] = 'D'\n",
    "                \n",
    "    # first class\n",
    "    if cabin_nan['pclass'].iloc[p] == 1 and cabin_nan['sex'].iloc[p] == 'male':\n",
    "        index = cabin_nan['passengerid'].iloc[p] - 1\n",
    "        p = np.random.randint(low=1, high=101, size=1, dtype=int)[0]\n",
    "        if p <= 22:\n",
    "            df.at[index,'cabin'] = 'l'\n",
    "        elif p > 22:\n",
    "                df.at[index,'cabin'] = 'D'\n",
    "    \n",
    "    if cabin_nan['pclass'].iloc[p] == 1 and cabin_nan['sex'].iloc[p] == 'female':\n",
    "        index = cabin_nan['passengerid'].iloc[p] - 1\n",
    "        df.at[index,'cabin'] = 'l'\n",
    "        \n",
    "        \n",
    "        \n",
    "cabin_nan =  df[df['cabin'].isna()] # update cabin_nan\n",
    "print('df cabin nans updated',len(cabin_nan)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d36061d",
   "metadata": {},
   "source": [
    "## other nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56607182",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fill fare nan as the average of 3 class . \n",
    "\n",
    "t_class = df[df['pclass'] == 3]\n",
    "t_class_mean = t_class['fare'].mean()\n",
    "df.at[1043, 'fare'] = t_class_mean\n",
    "\n",
    "# fill nan embarked to be an class of itself\n",
    "df.at[61, 'embarked'] = 'M'\n",
    "df.at[829, 'embarked'] = 'M'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f53e4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "title, last_name = parse_name(df) # parse names and fill name as last name to categorize it \n",
    "df['name'] = last_name \n",
    "# df['cabin'] = df['cabin'].fillna(5) # all the nans in cabin are a caegory 5 \n",
    "df = cat_to_numeric(df)\n",
    "\n",
    "survived = df['survived']\n",
    "passenger_id = df['passengerid'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec614e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived       1.000000\n",
       "sex            0.543351\n",
       "cabin          0.295153\n",
       "fare           0.257307\n",
       "embarked       0.118026\n",
       "parch          0.081629\n",
       "name           0.017314\n",
       "passengerid   -0.005007\n",
       "sibsp         -0.035322\n",
       "ticket        -0.047298\n",
       "age           -0.066088\n",
       "pclass        -0.338481\n",
       "Name: survived, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_mat = df.corr()\n",
    "corr_mat['survived'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29623f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(columns=['cabin', 'name', 'ticket']) # for now drop cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07d2659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['survived','passengerid','name', 'sibsp', 'ticket']) \n",
    "# 'name', 'sibsp', 'ticket' dropped those columns logic in unstandradized models file p value filter  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850fcf0e",
   "metadata": {},
   "source": [
    "# scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1389909",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_columns_selector = selector(dtype_exclude=int)\n",
    "categorical_columns_selector = selector(dtype_include=int)\n",
    "\n",
    "numerical_columns = numerical_columns_selector(df)\n",
    "categorical_columns = categorical_columns_selector(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf0d7d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'fare']\n",
      "['pclass', 'sex', 'parch', 'cabin', 'embarked']\n"
     ]
    }
   ],
   "source": [
    "print(numerical_columns)\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b7fb511",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "numerical_preprocessor = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d245683",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "    ('standard_scaler', numerical_preprocessor, numerical_columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93f5d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(preprocessor, SVC(kernel='rbf') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31bc9aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide back into train test sets \n",
    "df_train = df.iloc[:890,:]\n",
    "df_test = df.iloc[891:,:]\n",
    "\n",
    "x_train = df_train\n",
    "y_train = survived.iloc[:890]\n",
    "\n",
    "\n",
    "x_test = df_test\n",
    "y_test = survived.iloc[891:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4af8ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(x_train, y_train)\n",
    "y_train_pred = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f3391a",
   "metadata": {},
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7637112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rf\n",
    "# clf = LogisticRegression(random_state=9, max_iter=500, solver = 'newton-cg') \n",
    "# clf = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "# clf = SVC(kernel='poly')\n",
    "# clf = KNeighborsClassifier()\n",
    "# clf = GradientBoostingClassifier(n_estimators=40, learning_rate=0.2,max_depth=2, random_state=0)\n",
    "# clf = LinearSVC(random_state=0, tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc8fcef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.839\n",
      "precision : 0.878\n",
      "recall : 0.675\n",
      "f_score : 0.764\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f_1, support = precision_recall_fscore_support(y_train, y_train_pred, average='binary')\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print('accuracy :', np.round(accuracy,3))\n",
    "print('precision :', np.round(precision,3))\n",
    "print('recall :', np.round(recall,3))\n",
    "print('f_score :', np.round(f_1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee19c12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_avg_accuracy : 0.818\n",
      "cv_avg_precision 0.843\n",
      "cv_avg_recall 0.649\n",
      "cv_avg_fscore : 0.732\n"
     ]
    }
   ],
   "source": [
    "cv_5_accuracy = cross_val_score(model, x_train , y_train, cv=5, scoring='accuracy')\n",
    "cv_5_precision = cross_val_score(model, x_train , y_train, cv=5, scoring='precision')\n",
    "cv_5_recall = cross_val_score(model, x_train , y_train, cv=5, scoring='recall')\n",
    "cv_5_f1 = cross_val_score(model, x_train , y_train, cv=5, scoring='f1')\n",
    "\n",
    "print('cv_avg_accuracy :', np.round(cv_5_accuracy.mean(),3))\n",
    "print('cv_avg_precision', np.round(cv_5_precision.mean(),3))\n",
    "print('cv_avg_recall', np.round(cv_5_recall.mean(),3))\n",
    "print('cv_avg_fscore :', np.round(cv_5_f1.mean(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "549af6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[500  48]\n",
      " [116 226]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.91      0.86       548\n",
      "         1.0       0.82      0.66      0.73       342\n",
      "\n",
      "    accuracy                           0.82       890\n",
      "   macro avg       0.82      0.79      0.80       890\n",
      "weighted avg       0.82      0.82      0.81       890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(model, x_train, y_train, cv=3)\n",
    "cnf_mx = confusion_matrix(y_train, y_pred)\n",
    "print(cnf_mx)\n",
    "print(classification_report(y_train, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137128e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(model, x_train, y_train, cv=3, method = 'decision_function')\n",
    "precisions, recalls, thresholds_2 = precision_recall_curve(y_train, y_pred)\n",
    "plt.plot(thresholds_2, precisions[:-1], 'b--', label='Precision')\n",
    "plt.plot(thresholds_2, recalls[:-1], 'g-', label='Recall')\n",
    "plt.xlabel('Threshold')\n",
    "plt.legend(loc=('lower left'))\n",
    "plt.xlim([-2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recalls[:-1], precisions[:-1], 'b--')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c5e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds_1 = roc_curve(y_train, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\n",
    "display.plot()\n",
    "plt.show()\n",
    "                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6445bcab",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da16b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred = y_test_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5af55a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission_df = pd.DataFrame({'Passengerid': passenger_id[891:], 'Survived': y_test_pred})\n",
    "submission_df.to_csv('titanic_pred_16_retry.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e353f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
