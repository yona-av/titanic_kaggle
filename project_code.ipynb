{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d23bdae",
   "metadata": {},
   "source": [
    "# Titanic project code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6862c0f9",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e0488df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# import pre-processing modules s\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel \n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "# import classifiers\n",
    "# scale robust\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# scale sensitive\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# import evaluation modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support, classification_report\n",
    "from sklearn.metrics import  RocCurveDisplay, roc_auc_score, auc, roc_curve, PrecisionRecallDisplay, precision_recall_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f3a18",
   "metadata": {},
   "source": [
    "## Define Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab2d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse title and fam name from df \n",
    "def parse_name(df):\n",
    "    last_name = df['name'].apply(lambda x : x.split(', ')[0])\n",
    "    temp = df['name'].apply(lambda x : x.split(', ')[1])\n",
    "    title = temp.apply(lambda x : x.split('.')[0])\n",
    "    return title, last_name\n",
    "\n",
    "def cat_to_numeric(df):\n",
    "    cat_columns = df.select_dtypes(['object']).columns\n",
    "    df[cat_columns] = df[cat_columns].apply(lambda x: pd.factorize(x)[0])\n",
    "    return df \n",
    "\n",
    "def pvalue_filter(target_df, features_df, alpha): # returns a list of columns that are possible drop, p_val > alpha, corr, pval\n",
    "    features_columns_names = list(features_df)\n",
    "    target_column_name = list(target_df)\n",
    "    features_np = features_df.to_numpy()\n",
    "    target_np = target_df.to_numpy()\n",
    "    drop_index = []\n",
    "    p_val_list =[]\n",
    "    corr_list = []\n",
    "    \n",
    "    for i in range(len(features_columns_names)):\n",
    "        corr, p_val = sp.stats.pearsonr(features_np[:,i], target_np)\n",
    "        corr_list.append(round(corr,3))\n",
    "        if p_val > alpha:           # accept the null hypothesis, no statisitcal significance  \n",
    "            drop_index.append(i)\n",
    "            p_val_list.append(p_val)\n",
    "            \n",
    "    drop_col = [features_columns_names[i] for i in drop_index]\n",
    "    return drop_col, corr_list, p_val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8751f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(r\"C:/Users/Yehonatan/PycharmProject/DS/projects/titanic/ignore/test.csv\")\n",
    "train_set = pd.read_csv(r\"C:/Users/Yehonatan/PycharmProject/DS/projects/titanic/ignore/train.csv\")\n",
    "\n",
    "df_original = pd.concat([train_set,test_set], axis=0, ignore_index=True )\n",
    "df_train = (train_set.copy()).rename(columns=str.lower)\n",
    "df_test = (test_set.copy()).rename(columns=str.lower)\n",
    "\n",
    "df = (df_original.copy()).rename(columns=str.lower)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad4b333",
   "metadata": {},
   "source": [
    "For those who would like to see the [EDA notebook](https://github.com/yona-av/titanic_kaggle/blob/main/EDA_notebook.ipynb) now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f1f47a",
   "metadata": {},
   "source": [
    "# Deal with age Nans\n",
    " this code section deals with Nan values in the age column in few ways:\n",
    "- Those with the title Master are younger then 15 years, so they get the mean age of those under 15 years.\n",
    "- Lone passengers. they get the age mean by their gender    \n",
    "- One companion. I tried to to extract information through checking the companion's information \n",
    "- Hand fill values special cases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c717670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df age nans before methods 263\n",
      "df age nans after methods 0\n"
     ]
    }
   ],
   "source": [
    "age_nan = df[df['age'].isna()]  \n",
    "print('df age nans before methods',df['age'].isna().sum())\n",
    "title, last_name = parse_name(df)\n",
    "df['title'] = title\n",
    "df['last_name'] = last_name\n",
    "\n",
    "###### Deal with Masters  ############################################\n",
    "\n",
    "child_mean =  round(df[df[\"age\"] < 15 ]['age'].mean(numeric_only=True),2)\n",
    "df.loc[df['title'] == 'Master','age'] = df.loc[df['title'] == 'Master','age'].fillna(child_mean)\n",
    "age_nan = df[df['age'].isna()] # update age_nan\n",
    "\n",
    "####### Deal with lone passengers ############################################\n",
    "male_mean =  round(df[df[\"sex\"] == 'male']['age'].mean(numeric_only=True),2)\n",
    "female_mean =  round(df[df[\"sex\"] == 'female']['age'].mean(numeric_only=True),2)\n",
    "\n",
    "df.loc[(df['sibsp'] == 0) & (df['parch'] == 0) & (df['sex'] == 'male'), 'age'\n",
    "      ]= df.loc[(df['sibsp'] == 0) & (df['parch'] == 0) & (df['sex'] == 'male'), 'age'].fillna(male_mean)\n",
    "\n",
    "df.loc[(df['sibsp'] == 0) & (df['parch'] == 0) & (df['sex'] == 'female'), 'age'\n",
    "      ]= df.loc[(df['sibsp'] == 0) & (df['parch'] == 0) & (df['sex'] == 'female'), 'age'].fillna(female_mean)\n",
    "\n",
    "age_nan = df[df['age'].isna()] # update age_nan\n",
    "\n",
    "########## ONE companion (sibling or spouse) ############################################################\n",
    "\n",
    "one_comp_mean = round(df[(df['sibsp'] == 1) & (df['parch'] == 0)]['age'].mean(numeric_only=True),2)\n",
    "one_comp_df = df[(df['sibsp'] == 1) & (df['parch'] == 0)]\n",
    "one_comp_df_nan = one_comp_df[one_comp_df['age'].isna()]\n",
    "\n",
    "for i in range(len(one_comp_df_nan)):\n",
    "    for j in range(len(one_comp_df)):\n",
    "        #compare last name and make sure it isn't the same passenger\n",
    "        if (one_comp_df_nan['last_name'].iloc[i] == one_comp_df['last_name'].iloc[j]  \n",
    "            and one_comp_df_nan['passengerid'].iloc[i] != one_comp_df['passengerid'].iloc[j]):\n",
    "            \n",
    "            ix_nan = one_comp_df_nan['passengerid'].iloc[i] - 1 \n",
    "            ix = one_comp_df['passengerid'].iloc[j] -1 \n",
    "            df.at[ix_nan,'age'] = df.at[ix,'age']\n",
    "            \n",
    "age_nan = df[df['age'].isna()] # update the age_nan\n",
    "\n",
    "########## Special cases ############################################################\n",
    "# sage family\n",
    "#parents\n",
    "df.at[1233, 'age'] = male_mean\n",
    "df.at[1256, 'age'] = female_mean\n",
    "#kids\n",
    "df[df['last_name'] == 'Sage']['age'] = df[df['last_name'] == 'Sage']['age'].fillna(child_mean)\n",
    "\n",
    "# lebfre family\n",
    "df.at[1023, 'age'] = female_mean\n",
    "#kids\n",
    "df[df['last_name'] == 'lebfre']['age'] = df[df['last_name'] == 'lebfre']['age'].fillna(child_mean)\n",
    "\n",
    "#jhonston family\n",
    "#parents\n",
    "df.at[783, 'age'] = male_mean\n",
    "df.at[924, 'age'] = female_mean\n",
    "\n",
    "age_nan = df[df['age'].isna()] # update age_nan\n",
    "\n",
    "\n",
    "############ deal with the rest ########################################################################################\n",
    "df.loc[df['sex'] == 'male', 'age'] = df.loc[df['sex'] == 'male', 'age'].fillna(male_mean)\n",
    "df.loc[df['sex'] == 'female', 'age'] = df.loc[df['sex'] == 'female', 'age'].fillna(female_mean)\n",
    "age_nan = df[df['age'].isna()] # update age_nan\n",
    "print('df age nans after methods',df['age'].isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc362424",
   "metadata": {},
   "source": [
    "# Deal with cabin Nans\n",
    "this code section deals with Nan values in the cabin column in two ways:\n",
    "- By comparing the ticket numbers. If there is a similar ticket number and it has a cabin number, it seems like they share the same cabin.\n",
    "- Some passengers have the same fare but a different Pclass. The second method assumes that those in the same class who paid a same fare would be in close cabins. Thus, combining the ‘Pclass’ to the ‘fare’ column creates a new sub group. e.g: pclass :2 and fare: 7.25 would create a new cabin 27.25 or 37.25 if the passenger has Pclass 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25f26a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df cabin nans before methods 1014\n",
      "df df cabin nans after methods 0\n"
     ]
    }
   ],
   "source": [
    "cabin = df[~df['cabin'].isna()]\n",
    "cabin_nan =  df[df['cabin'].isna()]\n",
    "print('df cabin nans before methods',df['cabin'].isna().sum())\n",
    "\n",
    "################## deal with cabin nan by comparing the ticket number #########################################################\n",
    "for t in range(len(cabin['ticket'])):\n",
    "    for n in range(len(cabin_nan['ticket'])):\n",
    "        if cabin['ticket'].iloc[t] == cabin_nan['ticket'].iloc[n] :\n",
    "           \n",
    "            ix = cabin['passengerid'].iloc[t] - 1    \n",
    "            ix_nan = cabin_nan['passengerid'].iloc[n] - 1 \n",
    "            if ix != ix_nan:\n",
    "                # update the value of cabin_nan in the df\n",
    "                df.at[ix_nan,'cabin'] = df.at[ix,'cabin']\n",
    "\n",
    "\n",
    "cabin_nan =  df[df['cabin'].isna()] # update cabin_nan   \n",
    "\n",
    "################## deal with rest of Nans #########################################################\n",
    "\n",
    "# combine for each passenger 'pclass' and 'fare' and assume \n",
    "#that if they paid the same and were at the same class they were at the sme cabin\n",
    "\n",
    "cabin_nan['cabin'] = cabin_nan['pclass'].astype('string') + cabin_nan['fare'].astype('string')\n",
    "for i in range(len(cabin_nan)):\n",
    "    ix = cabin_nan['passengerid'].iloc[i] - 1\n",
    "    df.at[ix,'cabin'] = cabin_nan['cabin'].iloc[i]\n",
    "\n",
    "cabin_nan =  df[df['cabin'].isna()] # update cabin_nan\n",
    "\n",
    "########### special case #############################################################################\n",
    "df.at[1043,'cabin'] = 38.05 # explain 3 is pclass and added to fare value 8.05 \n",
    "cabin_nan =  df[df['cabin'].isna()] # update cabin_nan\n",
    "print('df df cabin nans after methods',len(cabin_nan))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95c87b1",
   "metadata": {},
   "source": [
    "# other Nans\n",
    "\n",
    "There are some special cases in other columns :\n",
    "- passenger 1044 gets the mean fare of 3rd class \n",
    "- passengers 62 and 830 get the most common embarking place 'S'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6b59530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill fare nan as the average of 3 class . \n",
    "\n",
    "t_class_mean = round(df[df[\"pclass\"] == 3 ]['fare'].mean(numeric_only=True),2)\n",
    "df.at[1043, 'fare'] = t_class_mean\n",
    "\n",
    "# fill nan embarked to be as most common embarking place \n",
    "df.at[61, 'embarked'] = 'S'\n",
    "df.at[829, 'embarked'] = 'S'\n",
    "\n",
    "survived = df['survived']\n",
    "passenger_id = df['passengerid'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3567356",
   "metadata": {},
   "source": [
    "## Decrease the number of categories in the column 'title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce467044",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['title'] = df['title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\n",
    "                                   'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "df['title'] = df['title'].replace(['Mlle','Ms' ], 'Miss')\n",
    "df['title'] = df['title'].replace('Mme', 'Mrs')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e69dfc",
   "metadata": {},
   "source": [
    "## Label the data numerically "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7038a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cat_to_numeric(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db91786",
   "metadata": {},
   "source": [
    "# check correlation and p-value\n",
    "This section checks linear correlation between the features to the target. In some cases there might be some nonlinear correlation , but it is still good to check whether there is strong linear correlation between features.\n",
    "A p-value test is performed to eliminate features that doesn't contribute and have no statistical significance  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c7ffa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived       1.000000\n",
       "sex            0.543351\n",
       "title          0.405788\n",
       "fare           0.257307\n",
       "cabin          0.218673\n",
       "embarked       0.106811\n",
       "parch          0.081629\n",
       "last_name      0.017314\n",
       "passengerid   -0.005007\n",
       "name          -0.005007\n",
       "sibsp         -0.035322\n",
       "ticket        -0.047298\n",
       "age           -0.065752\n",
       "pclass        -0.338481\n",
       "Name: survived, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_mat = df.corr()\n",
    "corr_mat['survived'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8aa440c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop those columns, p-value < 0.05 no statistical importance ['passengerid', 'name', 'age', 'sibsp', 'ticket', 'last_name']\n"
     ]
    }
   ],
   "source": [
    "df_train = df.iloc[:890,:]\n",
    "\n",
    "drop_col, corr_list, p_val_list = pvalue_filter(df_train['survived'], df_train.drop(columns=['survived']), 0.05)\n",
    "print('drop those columns, p-value < 0.05 no statistical importance',drop_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62201a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['survived','passengerid', 'name', 'sibsp', 'ticket', 'last_name','age']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9c74d5",
   "metadata": {},
   "source": [
    "# Create a model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb450664",
   "metadata": {},
   "source": [
    "## scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a1fef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_columns_selector = selector(dtype_exclude=int)\n",
    "categorical_columns_selector = selector(dtype_include=int)\n",
    "\n",
    "numerical_columns = numerical_columns_selector(df)\n",
    "categorical_columns = categorical_columns_selector(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb0a82e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continious features that are used : ['fare']\n",
      "categorical features that are used : ['pclass', 'sex', 'parch', 'cabin', 'embarked', 'title']\n"
     ]
    }
   ],
   "source": [
    "print('continious features that are used :', numerical_columns)\n",
    "print('categorical features that are used :', categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c98710",
   "metadata": {},
   "source": [
    "## Data encoding\n",
    "- One hot encoding for categorical features \n",
    "- Standard scaler for continuous features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad759712",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "numerical_preprocessor = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "    ('standard_scaler', numerical_preprocessor, numerical_columns)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d2333b",
   "metadata": {},
   "source": [
    "## Divide the data frame back to the original train and test sets   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3277ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide back into train test sets \n",
    "df_train = df.iloc[:890,:]\n",
    "df_test = df.iloc[891:,:]\n",
    "\n",
    "x_train = df_train\n",
    "y_train = survived.iloc[:890]\n",
    "\n",
    "\n",
    "x_test = df_test\n",
    "y_test = survived.iloc[891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed8c511",
   "metadata": {},
   "source": [
    "# Train few models for comparison "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad2ba73",
   "metadata": {},
   "source": [
    "## SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4d28809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC_accuracy : 0.820225\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(preprocessor, SVC())\n",
    "model = model.fit(x_train, y_train)\n",
    "y_train_pred = model.predict(x_train)\n",
    "\n",
    "svc_acc = np.round(cross_val_score(model, x_train , y_train, cv=5, scoring='accuracy').mean(),6)\n",
    "print('SVC_accuracy :',svc_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe6aca",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80d6fe08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_accuracy : 0.827\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(preprocessor, RandomForestClassifier(random_state=9) )\n",
    "model = model.fit(x_train, y_train)\n",
    "y_train_pred = model.predict(x_train)\n",
    "\n",
    "rf_acc = np.round(cross_val_score(model, x_train , y_train, cv=5, scoring='accuracy').mean(),3)\n",
    "print('RF_accuracy :', rf_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c857817",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd5b6d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic_Regression_accuracy : 0.83\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(preprocessor, LogisticRegression(random_state=9))\n",
    "model = model.fit(x_train, y_train)\n",
    "y_train_pred = model.predict(x_train)\n",
    "\n",
    "lg_acc = np.round(cross_val_score(model, x_train , y_train, cv=5, scoring='accuracy').mean(),3)\n",
    "print('Logistic_Regression_accuracy :', lg_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08df82ed",
   "metadata": {},
   "source": [
    "# SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "870bb8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD_accuracy : 0.749\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(preprocessor, SGDClassifier(max_iter=1000, tol=1e-3) )\n",
    "model = model.fit(x_train, y_train)\n",
    "y_train_pred = model.predict(x_train)\n",
    "\n",
    "sgd_acc =np.round(cross_val_score(model, x_train , y_train, cv=5, scoring='accuracy').mean(),3)\n",
    "print('SGD_accuracy :', sgd_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a34a550",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcea6a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB_accuracy : 0.82\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(preprocessor, XGBClassifier(n_estimators=100, objective='binary:logistic') )\n",
    "model = model.fit(x_train, y_train)\n",
    "y_train_pred = model.predict(x_train)\n",
    "\n",
    "xgb_acc = np.round(cross_val_score(model, x_train , y_train, cv=5, scoring='accuracy').mean(),3)\n",
    "print('XGB_accuracy :', xgb_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9229731",
   "metadata": {},
   "source": [
    "# KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f92553e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN_accuracy : 0.804\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(preprocessor, KNeighborsClassifier() )\n",
    "model = model.fit(x_train, y_train)\n",
    "y_train_pred = model.predict(x_train)\n",
    "\n",
    "knn_acc = np.round(cross_val_score(model, x_train , y_train, cv=5, scoring='accuracy').mean(),3)\n",
    "print('KNN_accuracy :', knn_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4bef5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kaggle score</th>\n",
       "      <th>Train score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.820225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.770</td>\n",
       "      <td>0.827000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.765</td>\n",
       "      <td>0.804000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.751</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Kaggle score  Train score\n",
       "Model                                         \n",
       "SVC                         0.801     0.820225\n",
       "SGD                         0.791     0.749000\n",
       "Logistic Regression         0.787     0.830000\n",
       "Random Forest               0.770     0.827000\n",
       "KNN                         0.765     0.804000\n",
       "XGBoost                     0.751     0.820000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Train score':[svc_acc, rf_acc, lg_acc, \n",
    "              sgd_acc, xgb_acc, knn_acc],\n",
    "    'Kaggle score':[0.801, 0.77, 0.787, 0.791, 0.751, 0.765 ],\n",
    "    \n",
    "    'Model':['SVC', 'Random Forest', 'Logistic Regression', \n",
    "              'SGD', 'XGBoost', 'KNN']})\n",
    "\n",
    "pd.pivot_table(models, index='Model', values=['Train score','Kaggle score']).sort_values(by='Kaggle score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd1fe6a",
   "metadata": {},
   "source": [
    "As it seen from the comparison of different results of the models. SVC performance was the best - gave the highest Kaggle accuracy score. So now we retrain the model with SVC and check if hyperparameters tuning, using Grid search will improve the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb1d440a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[481  67]\n",
      " [111 231]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.88      0.84       548\n",
      "         1.0       0.78      0.68      0.72       342\n",
      "\n",
      "    accuracy                           0.80       890\n",
      "   macro avg       0.79      0.78      0.78       890\n",
      "weighted avg       0.80      0.80      0.80       890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(model, x_train, y_train, cv=3)\n",
    "cnf_mx = confusion_matrix(y_train, y_pred)\n",
    "print(cnf_mx)\n",
    "print(classification_report(y_train, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99210b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'svc__C': [0.1,0.5, 1, 10,50,100,200,500],\n",
    "               'svc__kernel':['rbf','linear','poly'],\n",
    "               'svc__gamma': ['auto', 'scale'],\n",
    "               'svc__decision_function_shape': ['ovo', 'ovr']}]\n",
    "\n",
    "\n",
    "gd = GridSearchCV(model, param_grid=param_grid, verbose=True)\n",
    "gd.fit(x_train, y_train)\n",
    "\n",
    "print('best score after Gridsearch',gd.best_score_) \n",
    "\n",
    "print(gd.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a23bfb",
   "metadata": {},
   "source": [
    "## retrain the model with the new parameters\n",
    "After the hyperparameters tuning the accuracy on kaggle is 0.79425  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4f8edfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC_accuracy : 0.848315\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(preprocessor, SVC(C=500, decision_function_shape='ovo', gamma='auto'))\n",
    "model = model.fit(x_train, y_train)\n",
    "y_train_pred = model.predict(x_train)\n",
    "\n",
    "svc_acc = np.round(cross_val_score(model, x_train , y_train, cv=5, scoring='accuracy').mean(),6)\n",
    "print('SVC_accuracy :',svc_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea29dc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[488  60]\n",
      " [ 85 257]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.89      0.87       548\n",
      "         1.0       0.81      0.75      0.78       342\n",
      "\n",
      "    accuracy                           0.84       890\n",
      "   macro avg       0.83      0.82      0.83       890\n",
      "weighted avg       0.84      0.84      0.84       890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(model, x_train, y_train, cv=3)\n",
    "cnf_mx = confusion_matrix(y_train, y_pred)\n",
    "print(cnf_mx)\n",
    "print(classification_report(y_train, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdeb0cf",
   "metadata": {},
   "source": [
    "Even though the accuracy on the cross-validation folds was ~ 0.849 and the other metrics performed better, the accuracy on kaggle gave a slightly worse accuracy - 0.79425.\n",
    "So, I retrained the model with SVC with the default parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eaf56d",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fafb021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred = y_test_pred.astype(int)\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({'Passengerid': passenger_id[891:], 'Survived': y_test_pred})\n",
    "submission_df.to_csv('titanic_prediction.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
